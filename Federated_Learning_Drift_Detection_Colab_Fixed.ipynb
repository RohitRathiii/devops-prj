{
 "cells": [
  {
   "cell_type": "code",
   "source": "class BERTClassifier(nn.Module):\n    \\\"\\\"\\\"BERT-tiny classifier optimized for federated learning.\\\"\\\"\\\"\n\n    def __init__(self, model_name: str, num_classes: int = 4, dropout: float = 0.1):\n        super().__init__()\n        self.model_name = model_name\n        self.num_classes = num_classes\n\n        # Load BERT configuration and model\n        self.config = AutoConfig.from_pretrained(model_name)\n        self.bert = AutoModel.from_pretrained(model_name, config=self.config)\n\n        # Classification head\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Linear(self.config.hidden_size, num_classes)\n\n        # Initialize classifier weights\n        nn.init.normal_(self.classifier.weight, std=0.02)\n        nn.init.zeros_(self.classifier.bias)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        # BERT forward pass\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n\n        # Use [CLS] token representation\n        pooled_output = outputs.pooler_output\n        pooled_output = self.dropout(pooled_output)\n\n        # Classification\n        logits = self.classifier(pooled_output)\n\n        loss = None\n        if labels is not None:\n            loss_fn = nn.CrossEntropyLoss()\n            loss = loss_fn(logits, labels)\n\n        return {'loss': loss, 'logits': logits, 'hidden_states': outputs.last_hidden_state}\n\n    def get_embeddings(self, input_ids, attention_mask):\n        \\\"\\\"\\\"Extract embeddings for drift detection.\\\"\\\"\\\"\n        with torch.no_grad():\n            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n            # Return [CLS] token embeddings\n            return outputs.pooler_output\n\n\ndef create_model_and_tokenizer(config: Dict[str, Any], device: torch.device):\n    \\\"\\\"\\\"Create BERT model and tokenizer.\\\"\\\"\\\"\n    model_name = config['model']['model_name']\n    num_classes = config['model']['num_classes']\n    dropout = config['model']['dropout']\n\n    # Create tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n    # Create model\n    model = BERTClassifier(model_name, num_classes, dropout)\n    model = model.to(device)\n\n    # Enable mixed precision if GPU available\n    if device.type == 'cuda':\n        model = model.half()  # Use FP16 for memory efficiency\n\n    return model, tokenizer\n\n\nprint(\\\"âœ… BERT model implementation ready!\\\")\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ¤– BERT Model Implementation\n\nBERT-tiny classifier with GPU optimization for federated learning.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "main-title"
   },
   "source": [
    "# ðŸ”„ Federated LLM Drift Detection and Recovery System\n",
    "\n",
    "**A comprehensive standalone implementation for Google Colab with GPU acceleration**\n",
    "\n",
    "## ðŸ“‹ System Overview\n",
    "\n",
    "This notebook implements a sophisticated **multi-level drift detection architecture** for federated learning with BERT-tiny models:\n",
    "\n",
    "### ðŸ—ï¸ **Architecture Components**\n",
    "- **Client-Side Detection**: ADWIN (concept drift) + Evidently (data drift)\n",
    "- **Server-Side Detection**: MMD statistical test on embedding aggregates  \n",
    "- **Adaptive Mitigation**: FedAvg â†’ FedTrimmedAvg when drift detected\n",
    "- **Synthetic Drift Injection**: Vocabulary shift, label noise, distribution shift\n",
    "\n",
    "### ðŸŽ¯ **Key Features**\n",
    "- GPU-optimized for Google Colab (T4/P100/V100)\n",
    "- Real-time drift monitoring with visual analytics\n",
    "- Configurable drift scenarios and client heterogeneity\n",
    "- Production-ready federated learning pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## ðŸš€ Environment Setup and Dependencies\n",
    "\n",
    "First, let's install all required packages and configure the environment for optimal GPU performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-dependencies"
   },
   "outputs": [],
   "source": [
    "# Install required packages with GPU support\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q transformers[torch]>=4.56.0\n",
    "!pip install -q datasets>=4.0.0\n",
    "!pip install -q scikit-learn>=1.7.0\n",
    "!pip install -q flwr[simulation]>=1.20.0\n",
    "!pip install -q alibi-detect>=0.12.0\n",
    "!pip install -q evidently>=0.7.14\n",
    "!pip install -q river>=0.22.0\n",
    "!pip install -q nlpaug>=1.1.11\n",
    "!pip install -q matplotlib seaborn plotly\n",
    "!pip install -q pandas numpy scipy\n",
    "!pip install -q pyyaml\n",
    "\n",
    "print(\"âœ… All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpu-setup"
   },
   "outputs": [],
   "source": [
    "# Configure GPU and environment\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set environment variables for optimal performance\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "# Check GPU availability and configure\n",
    "def setup_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print(f\"ðŸŽ® GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"ðŸ“Š GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        \n",
    "        # Optimize memory usage\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        \n",
    "        # Set memory fraction to prevent OOM\n",
    "        if hasattr(torch.cuda, 'set_per_process_memory_fraction'):\n",
    "            torch.cuda.set_per_process_memory_fraction(0.9)\n",
    "            \n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print(\"âš ï¸ No GPU available, using CPU\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "device = setup_device()\n",
    "print(f\"ðŸ”§ Device configured: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any, Callable\n",
    "from collections import defaultdict\n",
    "\n",
    "# ML and DL imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Federated Learning\n",
    "import flwr as fl\n",
    "from flwr.simulation import start_simulation\n",
    "from flwr.common import Context, Parameters, Scalar\n",
    "from flwr.server.strategy import FedAvg\n",
    "\n",
    "# Drift Detection\n",
    "from alibi_detect import MMDDrift\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from river.drift import ADWIN\n",
    "import nlpaug.augmenter.word as naw\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"âœ… All imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-section"
   },
   "source": [
    "## âš™ï¸ Configuration and Constants\n",
    "\n",
    "Define all configuration parameters for the federated learning simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "configuration"
   },
   "outputs": [],
   "source": [
    "# Global Configuration for Federated Learning Drift Detection System\n",
    "CONFIG = {\n",
    "    # Model configuration\n",
    "    'model': {\n",
    "        'model_name': 'prajjwal1/bert-tiny',\n",
    "        'num_classes': 4,\n",
    "        'max_length': 128,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 2e-5,\n",
    "        'num_epochs': 3,\n",
    "        'warmup_steps': 100,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "\n",
    "    # Federated learning configuration\n",
    "    'federated': {\n",
    "        'num_clients': 10,\n",
    "        'alpha': 0.5,  # Dirichlet concentration for non-IID\n",
    "        'min_samples_per_client': 50\n",
    "    },\n",
    "\n",
    "    # Drift configuration\n",
    "    'drift': {\n",
    "        'injection_round': 25,\n",
    "        'drift_intensity': 0.3,\n",
    "        'affected_clients': [2, 5, 8],  # Which clients get drift\n",
    "        'drift_types': ['label_noise', 'vocab_shift']\n",
    "    },\n",
    "\n",
    "    # Drift detection configuration\n",
    "    'drift_detection': {\n",
    "        'adwin_delta': 0.002,\n",
    "        'mmd_p_val': 0.05,\n",
    "        'mmd_permutations': 100,\n",
    "        'evidently_threshold': 0.25,\n",
    "        'trimmed_beta': 0.2,  # For FedTrimmedAvg\n",
    "    },\n",
    "\n",
    "    # Simulation configuration\n",
    "    'simulation': {\n",
    "        'num_rounds': 50,\n",
    "        'fraction_fit': 1.0,\n",
    "        'fraction_evaluate': 1.0,\n",
    "        'min_fit_clients': 2,\n",
    "        'min_evaluate_clients': 2,\n",
    "        'mitigation_threshold': 0.3  # >30% clients reporting drift\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ… Configuration loaded:\")\n",
    "print(f\"ðŸ“Š Clients: {CONFIG['federated']['num_clients']}\")\n",
    "print(f\"ðŸ”„ Rounds: {CONFIG['simulation']['num_rounds']}\")\n",
    "print(f\"ðŸ’¥ Drift injection: Round {CONFIG['drift']['injection_round']}\")\n",
    "print(f\"ðŸŽ¯ Affected clients: {CONFIG['drift']['affected_clients']}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}