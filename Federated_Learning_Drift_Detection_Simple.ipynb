{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "main-title"
   },
   "source": [
    "# üîÑ Federated Learning Drift Detection System\n",
    "\n",
    "**Simplified standalone implementation for Google Colab**\n",
    "\n",
    "## üìã System Overview\n",
    "\n",
    "This notebook implements a **federated learning system with drift detection** using BERT-tiny models:\n",
    "\n",
    "### üèóÔ∏è **Core Features**\n",
    "- **Federated Learning**: Multi-client BERT training with Flower framework\n",
    "- **Drift Detection**: Statistical drift detection with automatic mitigation\n",
    "- **GPU Support**: Optimized for Google Colab T4/P100/V100\n",
    "- **Real-time Monitoring**: Performance tracking and visualization\n",
    "\n",
    "### üéØ **What You'll See**\n",
    "- Multi-client federated training on AG News dataset\n",
    "- Synthetic drift injection at round 12\n",
    "- Automatic detection and mitigation\n",
    "- Recovery performance analysis\n",
    "\n",
    "### üöÄ **Quick Start for Google Colab**\n",
    "1. **Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí Hardware accelerator: GPU\n",
    "2. **Run All Cells**: Runtime ‚Üí Run all (or Ctrl+F9)\n",
    "3. **Wait ~15-20 minutes**: The simulation will complete automatically\n",
    "4. **View Results**: Accuracy plots and performance metrics will be displayed\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## üöÄ Minimal Setup for Google Colab\n",
    "\n",
    "**Choose ONE of the installation methods below:**\n",
    "\n",
    "### Method 1: Standard Installation (Try this first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-dependencies"
   },
   "outputs": [],
   "source": [
    "# Install packages with conflict resolution\n",
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def safe_install(package):\n",
    "    \"\"\"Install package with error handling\"\"\"\n",
    "    try:\n",
    "        # Force reinstall to avoid conflicts\n",
    "        cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--force-reinstall\", \"--no-deps\", package]\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ {package}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è {package} failed: {result.stderr[:100]}\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {package} error: {str(e)[:100]}\")\n",
    "        return False\n",
    "\n",
    "print(\"üîß Installing core dependencies...\")\n",
    "\n",
    "# Install in specific order to avoid conflicts\n",
    "packages = [\n",
    "    \"numpy>=1.21.0\",\n",
    "    \"torch>=1.9.0\", \n",
    "    \"transformers>=4.20.0\",\n",
    "    \"datasets>=2.0.0\",\n",
    "    \"matplotlib>=3.0.0\",\n",
    "    \"scikit-learn>=1.0.0\"\n",
    "]\n",
    "\n",
    "for pkg in packages:\n",
    "    safe_install(pkg)\n",
    "\n",
    "print(\"\\nüì¶ Installing Flower framework...\")\n",
    "safe_install(\"flwr>=1.0.0\")\n",
    "\n",
    "print(\"\\nüéØ Fixing potential dependency issues...\")\n",
    "# Reinstall key packages that might conflict\n",
    "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", \"--force-reinstall\", \"setuptools\"], \n",
    "               capture_output=True)\n",
    "\n",
    "print(\"\\n‚úÖ Installation complete!\")\n",
    "print(\"üöÄ Ready to run federated learning simulation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports-setup"
   },
   "outputs": [],
   "source": [
    "# Import libraries and setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "# Transformers and datasets\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Flower federated learning\n",
    "import flwr as fl\n",
    "from flwr.simulation import start_simulation\n",
    "from flwr.common import Context\n",
    "from flwr.server.strategy import FedAvg\n",
    "\n",
    "# Configure environment\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üìä Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"‚ö†Ô∏è Using CPU (slower but will work)\")\n",
    "\n",
    "print(f\"‚úÖ Setup complete! Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Emergency Fallback (Use if Method 1 fails)\n",
    "\n",
    "If you encounter dependency conflicts with Method 1, run this simpler installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries with fallback handling\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "\n",
    "# Try to import transformers and datasets\n",
    "try:\n",
    "    from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "    from datasets import load_dataset\n",
    "    HAS_TRANSFORMERS = True\n",
    "    print(\"‚úÖ Transformers and datasets loaded\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Transformers/datasets import failed: {e}\")\n",
    "    HAS_TRANSFORMERS = False\n",
    "\n",
    "# Try to import Flower\n",
    "try:\n",
    "    import flwr as fl\n",
    "    from flwr.simulation import start_simulation\n",
    "    from flwr.common import Context\n",
    "    from flwr.server.strategy import FedAvg\n",
    "    HAS_FLOWER = True\n",
    "    print(\"‚úÖ Flower framework loaded\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ö†Ô∏è Flower import failed: {e}\")\n",
    "    HAS_FLOWER = False\n",
    "\n",
    "# Configure environment\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Setup device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"üìä Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    torch.cuda.empty_cache()\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"‚ö†Ô∏è Using CPU (slower but will work)\")\n",
    "\n",
    "print(f\"‚úÖ Setup complete! Device: {device}\")\n",
    "\n",
    "# Capability summary\n",
    "print(f\"\\nüéØ Available capabilities:\")\n",
    "print(f\"   PyTorch: ‚úÖ\")\n",
    "print(f\"   Transformers: {'‚úÖ' if HAS_TRANSFORMERS else '‚ùå'}\")\n",
    "print(f\"   Flower FL: {'‚úÖ' if HAS_FLOWER else '‚ùå'}\")\n",
    "\n",
    "if not HAS_TRANSFORMERS:\n",
    "    print(\"\\n‚ö†Ô∏è Running in limited mode - some features may not work\")\n",
    "    print(\"üí° Try the emergency installation method above\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-section"
   },
   "source": [
    "## ‚öôÔ∏è Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "config"
   },
   "outputs": [],
   "source": [
    "# Simple configuration for federated learning\n",
    "CONFIG = {\n",
    "    'model_name': 'prajjwal1/bert-tiny',\n",
    "    'num_classes': 4,\n",
    "    'max_length': 128,\n",
    "    'batch_size': 8,  # Reduced for better Colab compatibility\n",
    "    'learning_rate': 2e-5,\n",
    "    'num_clients': 6,  # Reduced for faster execution\n",
    "    'num_rounds': 20,  # Reduced for demonstration\n",
    "    'drift_round': 12, # Adjust proportionally\n",
    "    'affected_clients': [2, 4],  # Clients that will experience drift\n",
    "}\n",
    "\n",
    "print(\"üìä Configuration:\")\n",
    "print(\"üéØ Optimized for Google Colab demonstration\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"   {k}: {v}\")\n",
    "    \n",
    "print(f\"\\n‚è±Ô∏è Expected runtime: ~15-20 minutes\")\n",
    "print(f\"üíæ Memory usage: ~4-6 GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model-section"
   },
   "source": [
    "## ü§ñ BERT Model for Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model"
   },
   "outputs": [],
   "source": [
    "class SimpleBERTClassifier(nn.Module):\n",
    "    \"\"\"Simplified BERT classifier for federated learning.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str, num_classes: int = 4, fallback_mode: bool = False):\n",
    "        super().__init__()\n",
    "        self.fallback_mode = fallback_mode\n",
    "        \n",
    "        if not fallback_mode and HAS_TRANSFORMERS:\n",
    "            # Use real BERT\n",
    "            self.bert = AutoModel.from_pretrained(model_name)\n",
    "            hidden_size = self.bert.config.hidden_size\n",
    "        else:\n",
    "            # Use simple neural network fallback\n",
    "            print(\"‚ö†Ô∏è Using fallback neural network (no BERT)\")\n",
    "            self.bert = nn.Sequential(\n",
    "                nn.Embedding(10000, 128),  # Simple embedding\n",
    "                nn.LSTM(128, 64, batch_first=True),\n",
    "            )\n",
    "            hidden_size = 64\n",
    "            \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, labels=None):\n",
    "        if not self.fallback_mode and HAS_TRANSFORMERS:\n",
    "            # Real BERT forward\n",
    "            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            pooled_output = self.dropout(outputs.pooler_output)\n",
    "        else:\n",
    "            # Fallback forward\n",
    "            lstm_out, (h_n, c_n) = self.bert[1](self.bert[0](input_ids))\n",
    "            pooled_output = self.dropout(h_n[-1])  # Use last hidden state\n",
    "            \n",
    "        logits = self.classifier(pooled_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            loss = loss_fn(logits, labels)\n",
    "            \n",
    "        return {'loss': loss, 'logits': logits}\n",
    "    \n",
    "    def get_embeddings(self, input_ids, attention_mask):\n",
    "        \"\"\"Extract embeddings for drift detection.\"\"\"\n",
    "        with torch.no_grad():\n",
    "            if not self.fallback_mode and HAS_TRANSFORMERS:\n",
    "                outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "                return outputs.pooler_output\n",
    "            else:\n",
    "                lstm_out, (h_n, c_n) = self.bert[1](self.bert[0](input_ids))\n",
    "                return h_n[-1]\n",
    "\n",
    "\n",
    "def create_model_and_tokenizer():\n",
    "    \"\"\"Create model and tokenizer with fallback support.\"\"\"\n",
    "    if HAS_TRANSFORMERS:\n",
    "        model_name = CONFIG['model_name']\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = SimpleBERTClassifier(model_name, CONFIG['num_classes'], fallback_mode=False)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Creating fallback model without BERT\")\n",
    "        # Create dummy tokenizer\n",
    "        class DummyTokenizer:\n",
    "            def __call__(self, text, **kwargs):\n",
    "                # Simple word-based tokenization\n",
    "                words = str(text).lower().split()[:CONFIG['max_length']]\n",
    "                input_ids = [hash(w) % 10000 for w in words]\n",
    "                \n",
    "                # Pad or truncate\n",
    "                if len(input_ids) < CONFIG['max_length']:\n",
    "                    input_ids.extend([0] * (CONFIG['max_length'] - len(input_ids)))\n",
    "                else:\n",
    "                    input_ids = input_ids[:CONFIG['max_length']]\n",
    "                    \n",
    "                return {\n",
    "                    'input_ids': torch.tensor([input_ids]),\n",
    "                    'attention_mask': torch.tensor([[1] * len(input_ids)])\n",
    "                }\n",
    "        \n",
    "        tokenizer = DummyTokenizer()\n",
    "        model = SimpleBERTClassifier(\"dummy\", CONFIG['num_classes'], fallback_mode=True)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    return model, tokenizer\n",
    "\n",
    "print(\"‚úÖ BERT model with fallback support ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data-section"
   },
   "source": [
    "## üìä Data Handling and Federated Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "data"
   },
   "outputs": [],
   "source": [
    "class AGNewsDataset(Dataset):\n",
    "    \"\"\"Dataset for AG News classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = int(self.labels[idx])\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_length,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "\n",
    "def create_federated_data():\n",
    "    \"\"\"Create federated data splits.\"\"\"\n",
    "    print(\"üì• Loading AG News dataset...\")\n",
    "    \n",
    "    # Load dataset\n",
    "    dataset = load_dataset(\"ag_news\")\n",
    "    train_data = dataset['train']\n",
    "    test_data = dataset['test']\n",
    "    \n",
    "    # Create tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(CONFIG['model_name'])\n",
    "    \n",
    "    # Simple federated split (divide data equally among clients)\n",
    "    num_clients = CONFIG['num_clients']\n",
    "    train_texts = train_data['text'][:10000]  # Use subset for faster training\n",
    "    train_labels = train_data['label'][:10000]\n",
    "    \n",
    "    # Split data among clients\n",
    "    samples_per_client = len(train_texts) // num_clients\n",
    "    client_datasets = {}\n",
    "    \n",
    "    for i in range(num_clients):\n",
    "        start_idx = i * samples_per_client\n",
    "        end_idx = start_idx + samples_per_client\n",
    "        \n",
    "        client_texts = train_texts[start_idx:end_idx]\n",
    "        client_labels = train_labels[start_idx:end_idx]\n",
    "        \n",
    "        client_datasets[i] = AGNewsDataset(\n",
    "            client_texts, client_labels, tokenizer, CONFIG['max_length']\n",
    "        )\n",
    "        print(f\"üë§ Client {i}: {len(client_texts)} samples\")\n",
    "    \n",
    "    # Create test dataset\n",
    "    test_dataset = AGNewsDataset(\n",
    "        test_data['text'][:1000], test_data['label'][:1000], \n",
    "        tokenizer, CONFIG['max_length']\n",
    "    )\n",
    "    \n",
    "    return client_datasets, test_dataset, tokenizer\n",
    "\n",
    "print(\"‚úÖ Data handling ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "drift-section"
   },
   "source": [
    "## üîç Simple Drift Detection and Injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drift"
   },
   "outputs": [],
   "source": [
    "class SimpleDriftDetector:\n",
    "    \"\"\"Simple drift detector using accuracy monitoring.\"\"\"\n",
    "    \n",
    "    def __init__(self, window_size=5, threshold=0.05):\n",
    "        self.window_size = window_size\n",
    "        self.threshold = threshold\n",
    "        self.accuracy_history = []\n",
    "        \n",
    "    def update(self, accuracy):\n",
    "        \"\"\"Update with new accuracy and check for drift.\"\"\"\n",
    "        self.accuracy_history.append(accuracy)\n",
    "        \n",
    "        if len(self.accuracy_history) < self.window_size * 2:\n",
    "            return False\n",
    "        \n",
    "        # Compare recent vs older accuracy\n",
    "        recent_avg = np.mean(self.accuracy_history[-self.window_size:])\n",
    "        older_avg = np.mean(self.accuracy_history[-self.window_size*2:-self.window_size])\n",
    "        \n",
    "        # Detect significant drop\n",
    "        drift_detected = (older_avg - recent_avg) > self.threshold\n",
    "        return drift_detected\n",
    "\n",
    "\n",
    "def inject_drift(dataset, drift_intensity=0.3):\n",
    "    \"\"\"Simple drift injection by flipping some labels.\"\"\"\n",
    "    texts = dataset.texts.copy()\n",
    "    labels = list(dataset.labels)\n",
    "    \n",
    "    # Flip some labels randomly\n",
    "    num_to_flip = int(len(labels) * drift_intensity)\n",
    "    indices_to_flip = random.sample(range(len(labels)), num_to_flip)\n",
    "    \n",
    "    for idx in indices_to_flip:\n",
    "        # Change to random different label\n",
    "        current_label = labels[idx]\n",
    "        new_label = random.choice([i for i in range(4) if i != current_label])\n",
    "        labels[idx] = new_label\n",
    "    \n",
    "    return AGNewsDataset(texts, labels, dataset.tokenizer, dataset.max_length)\n",
    "\n",
    "print(\"‚úÖ Drift detection ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "client-section"
   },
   "source": [
    "## üë• Federated Learning Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "client"
   },
   "outputs": [],
   "source": [
    "class FedClient(fl.client.NumPyClient):\n",
    "    \"\"\"Federated learning client with drift detection.\"\"\"\n",
    "    \n",
    "    def __init__(self, client_id, model, train_loader, test_loader):\n",
    "        self.client_id = client_id\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.optimizer = optim.AdamW(model.parameters(), lr=CONFIG['learning_rate'])\n",
    "        self.drift_detector = SimpleDriftDetector()\n",
    "        \n",
    "    def get_parameters(self, config):\n",
    "        return [param.cpu().numpy() for param in self.model.parameters()]\n",
    "    \n",
    "    def set_parameters(self, parameters):\n",
    "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
    "        state_dict = {k: torch.tensor(v) for k, v in params_dict}\n",
    "        self.model.load_state_dict(state_dict, strict=True)\n",
    "    \n",
    "    def fit(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        \n",
    "        # Train for one epoch\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch in self.train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            outputs = self.model(input_ids, attention_mask, labels)\n",
    "            loss = outputs['loss']\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs['logits'], 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        \n",
    "        # Detect drift\n",
    "        drift_detected = self.drift_detector.update(accuracy / 100)\n",
    "        \n",
    "        return (\n",
    "            self.get_parameters({}), \n",
    "            len(self.train_loader.dataset),\n",
    "            {\n",
    "                'train_loss': total_loss / len(self.train_loader),\n",
    "                'train_accuracy': accuracy,\n",
    "                'drift_detected': drift_detected\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def evaluate(self, parameters, config):\n",
    "        self.set_parameters(parameters)\n",
    "        \n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in self.test_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = self.model(input_ids, attention_mask, labels)\n",
    "                loss = outputs['loss']\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs['logits'], 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        accuracy = 100 * correct / total\n",
    "        return total_loss / len(self.test_loader), len(self.test_loader.dataset), {'accuracy': accuracy}\n",
    "\n",
    "print(\"‚úÖ Federated client ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "server-section"
   },
   "source": [
    "## üñ•Ô∏è Federated Server with Drift-Aware Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "server"
   },
   "outputs": [],
   "source": [
    "class DriftAwareStrategy(FedAvg):\n",
    "    \"\"\"Federated averaging strategy with drift detection.\"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.drift_detected = False\n",
    "        self.round_metrics = []\n",
    "        \n",
    "    def aggregate_fit(self, server_round, results, failures):\n",
    "        \"\"\"Aggregate training results with drift detection.\"\"\"\n",
    "        print(f\"\\nüîÑ Round {server_round}: Processing {len(results)} clients\")\n",
    "        \n",
    "        # Check for drift signals\n",
    "        drift_count = sum(1 for _, fit_res in results \n",
    "                         if fit_res.metrics.get('drift_detected', False))\n",
    "        drift_rate = drift_count / len(results) if results else 0\n",
    "        \n",
    "        if drift_rate > 0.3:  # More than 30% clients detect drift\n",
    "            if not self.drift_detected:\n",
    "                print(f\"üö® DRIFT DETECTED! {drift_count}/{len(results)} clients affected\")\n",
    "                self.drift_detected = True\n",
    "            else:\n",
    "                print(f\"üõ°Ô∏è Continuing drift mitigation ({drift_count}/{len(results)} affected)\")\n",
    "        \n",
    "        # Use standard aggregation (could implement robust aggregation here)\n",
    "        aggregated_weights, aggregated_metrics = super().aggregate_fit(\n",
    "            server_round, results, failures\n",
    "        )\n",
    "        \n",
    "        return aggregated_weights, aggregated_metrics\n",
    "    \n",
    "    def aggregate_evaluate(self, server_round, results, failures):\n",
    "        \"\"\"Aggregate evaluation results.\"\"\"\n",
    "        if not results:\n",
    "            return None, {}\n",
    "        \n",
    "        # Calculate metrics\n",
    "        total_examples = sum(r[1] for r in results)\n",
    "        weighted_acc = sum(r[1] * r[2]['accuracy'] for r in results) / total_examples\n",
    "        weighted_loss = sum(r[0] * r[1] for r in results) / total_examples\n",
    "        \n",
    "        accuracies = [r[2]['accuracy'] for r in results]\n",
    "        fairness_gap = max(accuracies) - min(accuracies)\n",
    "        \n",
    "        metrics = {\n",
    "            'global_accuracy': weighted_acc,\n",
    "            'global_loss': weighted_loss,\n",
    "            'fairness_gap': fairness_gap,\n",
    "            'drift_detected': self.drift_detected\n",
    "        }\n",
    "        \n",
    "        self.round_metrics.append({\n",
    "            'round': server_round,\n",
    "            **metrics\n",
    "        })\n",
    "        \n",
    "        print(f\"üìä Global Accuracy: {weighted_acc:.2f}%\")\n",
    "        print(f\"‚öñÔ∏è Fairness Gap: {fairness_gap:.2f}%\")\n",
    "        \n",
    "        return weighted_loss, metrics\n",
    "\n",
    "print(\"‚úÖ Drift-aware server strategy ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "simulation-section"
   },
   "source": [
    "## üéÆ Main Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "simulation"
   },
   "outputs": [],
   "source": [
    "def run_federated_simulation():\n",
    "    \"\"\"Run the complete federated learning simulation.\"\"\"\n",
    "    print(\"üöÄ Starting Federated Learning Simulation...\")\n",
    "    \n",
    "    # Prepare data\n",
    "    client_datasets, test_dataset, tokenizer = create_federated_data()\n",
    "    \n",
    "    # Track drift injection\n",
    "    drift_injected = False\n",
    "    \n",
    "    def client_fn(context: Context):\n",
    "        \"\"\"Create client for simulation.\"\"\"\n",
    "        nonlocal drift_injected\n",
    "        \n",
    "        # Get client ID from node config\n",
    "        client_id = int(context.node_config.get(\"client_id\", 0))\n",
    "        \n",
    "        # Inject drift at specified round for affected clients\n",
    "        if (hasattr(context, 'state') and \n",
    "            context.state.round >= CONFIG['drift_round'] and \n",
    "            not drift_injected and \n",
    "            client_id in CONFIG['affected_clients']):\n",
    "            \n",
    "            print(f\"üí• Injecting drift to client {client_id}\")\n",
    "            client_datasets[client_id] = inject_drift(client_datasets[client_id])\n",
    "            drift_injected = True\n",
    "        \n",
    "        # Create model and data loaders\n",
    "        model, _ = create_model_and_tokenizer()\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            client_datasets[client_id], \n",
    "            batch_size=CONFIG['batch_size'], \n",
    "            shuffle=True\n",
    "        )\n",
    "        \n",
    "        test_loader = DataLoader(\n",
    "            test_dataset, \n",
    "            batch_size=CONFIG['batch_size'], \n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        return FedClient(client_id, model, train_loader, test_loader).to_client()\n",
    "    \n",
    "    # Create strategy\n",
    "    strategy = DriftAwareStrategy(\n",
    "        fraction_fit=1.0,\n",
    "        fraction_evaluate=1.0,\n",
    "        min_fit_clients=2,\n",
    "        min_evaluate_clients=2\n",
    "    )\n",
    "    \n",
    "    # Run simulation with proper resource allocation\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Use CPU-only simulation to avoid GPU memory issues in Colab\n",
    "    client_resources = {\"num_cpus\": 1.0, \"num_gpus\": 0.0}\n",
    "    if device.type == 'cuda':\n",
    "        # Small GPU allocation if available\n",
    "        client_resources[\"num_gpus\"] = 0.1\n",
    "    \n",
    "    try:\n",
    "        history = start_simulation(\n",
    "            client_fn=client_fn,\n",
    "            num_clients=CONFIG['num_clients'],\n",
    "            config=fl.server.ServerConfig(num_rounds=CONFIG['num_rounds']),\n",
    "            strategy=strategy,\n",
    "            client_resources=client_resources,\n",
    "            ray_init_args={\"include_dashboard\": False, \"ignore_reinit_error\": True}\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Simulation with Ray failed: {e}\")\n",
    "        print(\"üîÑ Trying simplified simulation...\")\n",
    "        # Fallback to simple sequential simulation\n",
    "        history = run_simple_simulation(strategy, client_datasets, test_dataset)\n",
    "    \n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Simulation completed in {execution_time/60:.1f} minutes!\")\n",
    "    \n",
    "    return history, strategy\n",
    "\n",
    "\n",
    "def run_simple_simulation(strategy, client_datasets, test_dataset):\n",
    "    \"\"\"Fallback simplified simulation without Ray.\"\"\"\n",
    "    print(\"üîÑ Running simplified sequential simulation...\")\n",
    "    \n",
    "    # Create a simple history object\n",
    "    class SimpleHistory:\n",
    "        def __init__(self):\n",
    "            self.metrics_centralized = []\n",
    "    \n",
    "    history = SimpleHistory()\n",
    "    \n",
    "    # Initialize global model\n",
    "    global_model, tokenizer = create_model_and_tokenizer()\n",
    "    global_params = [param.cpu().numpy() for param in global_model.parameters()]\n",
    "    \n",
    "    # Simple simulation loop\n",
    "    for round_num in range(1, CONFIG['num_rounds'] + 1):\n",
    "        print(f\"\\nüîÑ Round {round_num}\")\n",
    "        \n",
    "        # Select subset of clients\n",
    "        selected_clients = list(range(min(4, CONFIG['num_clients'])))\n",
    "        round_results = []\n",
    "        \n",
    "        for client_id in selected_clients:\n",
    "            # Create client\n",
    "            model, _ = create_model_and_tokenizer()\n",
    "            train_loader = DataLoader(client_datasets[client_id], batch_size=CONFIG['batch_size'])\n",
    "            test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'])\n",
    "            \n",
    "            client = FedClient(client_id, model, train_loader, test_loader)\n",
    "            \n",
    "            # Inject drift if needed\n",
    "            if (round_num >= CONFIG['drift_round'] and \n",
    "                client_id in CONFIG['affected_clients']):\n",
    "                client_datasets[client_id] = inject_drift(client_datasets[client_id])\n",
    "                train_loader = DataLoader(client_datasets[client_id], batch_size=CONFIG['batch_size'])\n",
    "                client = FedClient(client_id, model, train_loader, test_loader)\n",
    "            \n",
    "            # Train client\n",
    "            params, num_samples, fit_metrics = client.fit(global_params, {})\n",
    "            \n",
    "            # Evaluate client\n",
    "            loss, num_samples, eval_metrics = client.evaluate(params, {})\n",
    "            \n",
    "            round_results.append((eval_metrics['accuracy'], num_samples))\n",
    "        \n",
    "        # Calculate global metrics\n",
    "        total_samples = sum(num_samples for _, num_samples in round_results)\n",
    "        global_accuracy = sum(acc * num_samples for acc, num_samples in round_results) / total_samples\n",
    "        \n",
    "        accuracies = [acc for acc, _ in round_results]\n",
    "        fairness_gap = max(accuracies) - min(accuracies) if accuracies else 0\n",
    "        \n",
    "        # Store metrics\n",
    "        metrics = {\n",
    "            'global_accuracy': global_accuracy,\n",
    "            'fairness_gap': fairness_gap,\n",
    "            'drift_detected': round_num >= CONFIG['drift_round']\n",
    "        }\n",
    "        \n",
    "        history.metrics_centralized.append((round_num, metrics))\n",
    "        print(f\"üìä Accuracy: {global_accuracy:.2f}%, Gap: {fairness_gap:.2f}%\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"‚úÖ Simulation function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualization-section"
   },
   "source": [
    "## üìà Results Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "visualization"
   },
   "outputs": [],
   "source": [
    "def analyze_results(history, strategy):\n",
    "    \"\"\"Analyze and visualize simulation results.\"\"\"\n",
    "    print(\"üìä Analyzing results...\")\n",
    "    \n",
    "    # Extract metrics\n",
    "    rounds = []\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    fairness_gaps = []\n",
    "    \n",
    "    if hasattr(history, 'metrics_centralized'):\n",
    "        for round_num, metrics in history.metrics_centralized:\n",
    "            rounds.append(round_num)\n",
    "            accuracies.append(metrics.get('global_accuracy', 0))\n",
    "            fairness_gaps.append(metrics.get('fairness_gap', 0))\n",
    "    \n",
    "    # Create visualization\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "    \n",
    "    # Plot accuracy\n",
    "    ax1.plot(rounds, accuracies, 'b-', linewidth=2, label='Global Accuracy')\n",
    "    ax1.axvline(x=CONFIG['drift_round'], color='red', linestyle='--', \n",
    "                alpha=0.7, label=f'Drift Injection (Round {CONFIG[\"drift_round\"]})')\n",
    "    ax1.set_xlabel('Round')\n",
    "    ax1.set_ylabel('Accuracy (%)')\n",
    "    ax1.set_title('üéØ Global Accuracy Over Time')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot fairness gap\n",
    "    ax2.plot(rounds, fairness_gaps, 'g-', linewidth=2, label='Fairness Gap')\n",
    "    ax2.axvline(x=CONFIG['drift_round'], color='red', linestyle='--', alpha=0.7)\n",
    "    ax2.set_xlabel('Round')\n",
    "    ax2.set_ylabel('Fairness Gap (%)')\n",
    "    ax2.set_title('‚öñÔ∏è Client Fairness Gap')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary\n",
    "    if accuracies:\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üéØ SIMULATION SUMMARY\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"üìä Final Accuracy: {accuracies[-1]:.2f}%\")\n",
    "        print(f\"üìà Peak Accuracy: {max(accuracies):.2f}%\")\n",
    "        print(f\"‚öñÔ∏è Final Fairness Gap: {fairness_gaps[-1]:.2f}%\")\n",
    "        \n",
    "        # Calculate recovery if drift was detected\n",
    "        if len(accuracies) > CONFIG['drift_round']:\n",
    "            pre_drift = np.mean(accuracies[:CONFIG['drift_round']])\n",
    "            post_drift = accuracies[-1]\n",
    "            recovery_rate = post_drift / pre_drift\n",
    "            print(f\"üîÑ Pre-drift accuracy: {pre_drift:.2f}%\")\n",
    "            print(f\"üé≠ Post-drift accuracy: {post_drift:.2f}%\")\n",
    "            print(f\"üí™ Recovery rate: {recovery_rate:.2%}\")\n",
    "        \n",
    "        print(f\"üõ°Ô∏è Drift detected: {strategy.drift_detected}\")\n",
    "        print(f\"üéØ Affected clients: {CONFIG['affected_clients']}\")\n",
    "        print(\"=\"*60)\n",
    "\n",
    "print(\"‚úÖ Analysis function ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "run-section"
   },
   "source": [
    "## üöÄ Run the Complete Simulation\n",
    "\n",
    "**Execute this cell to run the federated learning experiment with drift detection!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "run-simulation"
   },
   "outputs": [],
   "source": [
    "# Run the complete federated learning simulation\n",
    "print(\"üé¨ Starting Federated Learning Drift Detection Experiment!\")\n",
    "print(f\"üìä Configuration: {CONFIG['num_clients']} clients, {CONFIG['num_rounds']} rounds\")\n",
    "print(f\"üí• Drift injection: Round {CONFIG['drift_round']} ‚Üí Clients {CONFIG['affected_clients']}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "try:\n",
    "    # Run simulation\n",
    "    history, strategy = run_federated_simulation()\n",
    "    \n",
    "    # Analyze results\n",
    "    analyze_results(history, strategy)\n",
    "    \n",
    "    print(\"\\nüéâ Experiment completed successfully!\")\n",
    "    print(\"‚úÖ You should see:\")\n",
    "    print(\"   - Accuracy drop after drift injection\")\n",
    "    print(\"   - Drift detection alerts in the logs\")\n",
    "    print(\"   - Recovery performance metrics\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Simulation failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "usage-tips"
   },
   "source": [
    "## üí° Usage Tips\n",
    "\n",
    "### üéõÔ∏è **Customization Options**\n",
    "\n",
    "You can modify the `CONFIG` dictionary above to experiment with:\n",
    "\n",
    "- **`num_clients`**: Number of federated clients (2-20)\n",
    "- **`num_rounds`**: Training rounds (10-50)\n",
    "- **`drift_round`**: When to inject drift (< num_rounds)\n",
    "- **`affected_clients`**: Which clients experience drift\n",
    "\n",
    "### üöÄ **For Faster Testing**\n",
    "```python\n",
    "CONFIG.update({\n",
    "    'num_clients': 4,\n",
    "    'num_rounds': 15,\n",
    "    'drift_round': 8\n",
    "})\n",
    "```\n",
    "\n",
    "### üìä **What to Look For**\n",
    "- **Baseline**: Steady accuracy improvement in early rounds\n",
    "- **Drift Impact**: Accuracy drop after injection round\n",
    "- **Detection**: \"DRIFT DETECTED\" messages in logs\n",
    "- **Recovery**: Gradual accuracy improvement after detection\n",
    "\n",
    "### üîß **Troubleshooting**\n",
    "- **Memory Error**: Reduce `batch_size` to 8 or `num_clients` to 4\n",
    "- **Slow Training**: Enable GPU in Colab (Runtime ‚Üí Change runtime type)\n",
    "- **Import Errors**: Restart runtime and re-run setup cells\n",
    "\n",
    "---\n",
    "**üéØ This simplified implementation demonstrates the core concepts of federated learning with drift detection while avoiding complex dependency conflicts!**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
