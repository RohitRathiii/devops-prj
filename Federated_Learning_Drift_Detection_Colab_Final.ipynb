{
 "cells": [
  {
   "cell_type": "markdown",
   "source": "## ðŸ“Š Data Handling and Federated Partitioning\n\nAG News dataset loading, preprocessing, and non-IID partitioning with drift injection capabilities.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class BERTClassifier(nn.Module):\n    \\\"\\\"\\\"BERT-tiny classifier optimized for federated learning.\\\"\\\"\\\"\n\n    def __init__(self, model_name: str, num_classes: int = 4, dropout: float = 0.1):\n        super().__init__()\n        self.model_name = model_name\n        self.num_classes = num_classes\n\n        # Load BERT configuration and model\n        self.config = AutoConfig.from_pretrained(model_name)\n        self.bert = AutoModel.from_pretrained(model_name, config=self.config)\n\n        # Classification head\n        self.dropout = nn.Dropout(dropout)\n        self.classifier = nn.Linear(self.config.hidden_size, num_classes)\n\n        # Initialize classifier weights\n        nn.init.normal_(self.classifier.weight, std=0.02)\n        nn.init.zeros_(self.classifier.bias)\n\n    def forward(self, input_ids, attention_mask, labels=None):\n        # BERT forward pass\n        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n\n        # Use [CLS] token representation\n        pooled_output = outputs.pooler_output\n        pooled_output = self.dropout(pooled_output)\n\n        # Classification\n        logits = self.classifier(pooled_output)\n\n        loss = None\n        if labels is not None:\n            loss_fn = nn.CrossEntropyLoss()\n            loss = loss_fn(logits, labels)\n\n        return {'loss': loss, 'logits': logits, 'hidden_states': outputs.last_hidden_state}\n\n    def get_embeddings(self, input_ids, attention_mask):\n        \\\"\\\"\\\"Extract embeddings for drift detection.\\\"\\\"\\\"\n        with torch.no_grad():\n            outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n            # Return [CLS] token embeddings\n            return outputs.pooler_output\n\n\ndef create_model_and_tokenizer(config: Dict[str, Any], device: torch.device):\n    \\\"\\\"\\\"Create BERT model and tokenizer.\\\"\\\"\\\"\n    model_name = config['model']['model_name']\n    num_classes = config['model']['num_classes']\n    dropout = config['model']['dropout']\n\n    # Create tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n    # Create model\n    model = BERTClassifier(model_name, num_classes, dropout)\n    model = model.to(device)\n\n    # Enable mixed precision if GPU available\n    if device.type == 'cuda':\n        try:\n            model = model.half()  # Use FP16 for memory efficiency\n            print(\\\"ðŸš€ FP16 mixed precision enabled\\\")\\n        except:\\n            print(\\\"âš ï¸ FP16 not supported, using FP32\\\")\\n\\n    return model, tokenizer\\n\\n\\nprint(\\\"âœ… BERT model implementation ready!\\\")\"",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## ðŸ¤– BERT Model Implementation\n\nBERT-tiny classifier with GPU optimization for federated learning.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "main-title"
   },
   "source": [
    "# ðŸ”„ Federated LLM Drift Detection and Recovery System\n",
    "\n",
    "**A comprehensive standalone implementation for Google Colab with GPU acceleration**\n",
    "\n",
    "## ðŸ“‹ System Overview\n",
    "\n",
    "This notebook implements a sophisticated **multi-level drift detection architecture** for federated learning with BERT-tiny models:\n",
    "\n",
    "### ðŸ—ï¸ **Architecture Components**\n",
    "- **Client-Side Detection**: ADWIN (concept drift) + Evidently (data drift)\n",
    "- **Server-Side Detection**: MMD statistical test on embedding aggregates  \n",
    "- **Adaptive Mitigation**: FedAvg â†’ FedTrimmedAvg when drift detected\n",
    "- **Synthetic Drift Injection**: Vocabulary shift, label noise, distribution shift\n",
    "\n",
    "### ðŸŽ¯ **Key Features**\n",
    "- GPU-optimized for Google Colab (T4/P100/V100)\n",
    "- Real-time drift monitoring with visual analytics\n",
    "- Configurable drift scenarios and client heterogeneity\n",
    "- Production-ready federated learning pipeline\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-section"
   },
   "source": [
    "## ðŸš€ Environment Setup and Dependencies\n",
    "\n",
    "**Important**: Restart runtime after running this cell to avoid dependency conflicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-dependencies"
   },
   "outputs": [],
   "source": [
    "# Fix dependency conflicts and install packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"--no-deps\", package])\n",
    "        print(f\"âœ… {package} installed successfully\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ {package} installation issue: {e}\")\n",
    "\n",
    "# Core ML packages (install without dependencies to avoid conflicts)\n",
    "print(\"ðŸ“¦ Installing core packages...\")\n",
    "!pip install -q --upgrade pip\n",
    "\n",
    "# Install PyTorch with CUDA support\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "\n",
    "# Install essential packages\n",
    "!pip install -q transformers>=4.30.0\n",
    "!pip install -q datasets>=2.0.0\n",
    "!pip install -q scikit-learn>=1.0.0\n",
    "!pip install -q pandas>=1.3.0\n",
    "!pip install -q numpy>=1.21.0\n",
    "!pip install -q matplotlib seaborn plotly\n",
    "\n",
    "# Install Flower for federated learning\n",
    "!pip install -q flwr>=1.0.0\n",
    "\n",
    "# Install drift detection packages (with fallbacks)\n",
    "try:\n",
    "    !pip install -q river>=0.20.0\n",
    "    print(\"âœ… River (ADWIN) installed\")\n",
    "except:\n",
    "    print(\"âš ï¸ River installation failed - will use fallback drift detection\")\n",
    "\n",
    "try:\n",
    "    !pip install -q alibi-detect>=0.11.0\n",
    "    print(\"âœ… Alibi-detect (MMD) installed\")\n",
    "except:\n",
    "    print(\"âš ï¸ Alibi-detect installation failed - will use fallback MMD\")\n",
    "\n",
    "try:\n",
    "    !pip install -q evidently>=0.4.0\n",
    "    print(\"âœ… Evidently installed\")\n",
    "except:\n",
    "    print(\"âš ï¸ Evidently installation failed - will use fallback data drift detection\")\n",
    "\n",
    "try:\n",
    "    !pip install -q nlpaug>=1.1.0\n",
    "    print(\"âœ… NLPAug installed\")\n",
    "except:\n",
    "    print(\"âš ï¸ NLPAug installation failed - will use simplified drift injection\")\n",
    "\n",
    "print(\"\\nðŸ”„ **IMPORTANT**: Please restart the runtime now (Runtime â†’ Restart runtime)\")\n",
    "print(\"Then run the next cell to continue with the setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpu-setup"
   },
   "outputs": [],
   "source": [
    "# Configure GPU and environment (Run after restart)\n",
    "import torch\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set environment variables for optimal performance\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "\n",
    "# Check GPU availability and configure\n",
    "def setup_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "        print(f\"ðŸŽ® GPU Available: {torch.cuda.get_device_name(0)}\")\n",
    "        print(f\"ðŸ“Š GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "        \n",
    "        # Optimize memory usage\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        \n",
    "        # Set memory fraction to prevent OOM\n",
    "        if hasattr(torch.cuda, 'set_per_process_memory_fraction'):\n",
    "            torch.cuda.set_per_process_memory_fraction(0.8)\n",
    "            \n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "        print(\"âš ï¸ No GPU available, using CPU\")\n",
    "    \n",
    "    return device\n",
    "\n",
    "device = setup_device()\n",
    "print(f\"ðŸ”§ Device configured: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "# Import all required libraries with fallback handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any, Callable\n",
    "from collections import defaultdict\n",
    "\n",
    "# ML and DL imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Federated Learning\n",
    "import flwr as fl\n",
    "from flwr.simulation import start_simulation\n",
    "from flwr.common import Context, Parameters, Scalar\n",
    "from flwr.server.strategy import FedAvg\n",
    "\n",
    "# Drift Detection imports with fallbacks\n",
    "DRIFT_PACKAGES = {\n",
    "    'river': False,\n",
    "    'alibi_detect': False,\n",
    "    'evidently': False,\n",
    "    'nlpaug': False\n",
    "}\n",
    "\n",
    "try:\n",
    "    from river.drift import ADWIN\n",
    "    DRIFT_PACKAGES['river'] = True\n",
    "    print(\"âœ… River (ADWIN) imported\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ River not available - using fallback ADWIN\")\n",
    "    \n",
    "try:\n",
    "    from alibi_detect import MMDDrift\n",
    "    DRIFT_PACKAGES['alibi_detect'] = True\n",
    "    print(\"âœ… Alibi-detect (MMD) imported\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ Alibi-detect not available - using fallback MMD\")\n",
    "\n",
    "try:\n",
    "    from evidently.report import Report\n",
    "    from evidently.metric_preset import DataDriftPreset\n",
    "    DRIFT_PACKAGES['evidently'] = True\n",
    "    print(\"âœ… Evidently imported\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ Evidently not available - using fallback data drift detection\")\n",
    "\n",
    "try:\n",
    "    import nlpaug.augmenter.word as naw\n",
    "    DRIFT_PACKAGES['nlpaug'] = True\n",
    "    print(\"âœ… NLPAug imported\")\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ NLPAug not available - using simplified drift injection\")\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(f\"\\nâœ… All imports loaded successfully!\")\n",
    "print(f\"ðŸ“¦ Available packages: {[k for k, v in DRIFT_PACKAGES.items() if v]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config-section"
   },
   "source": [
    "## âš™ï¸ Configuration and Constants\n",
    "\n",
    "Define all configuration parameters for the federated learning simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "configuration"
   },
   "outputs": [],
   "source": [
    "# Global Configuration for Federated Learning Drift Detection System\n",
    "CONFIG = {\n",
    "    # Model configuration\n",
    "    'model': {\n",
    "        'model_name': 'prajjwal1/bert-tiny',\n",
    "        'num_classes': 4,\n",
    "        'max_length': 128,\n",
    "        'batch_size': 16,\n",
    "        'learning_rate': 2e-5,\n",
    "        'num_epochs': 3,\n",
    "        'warmup_steps': 100,\n",
    "        'dropout': 0.1\n",
    "    },\n",
    "\n",
    "    # Federated learning configuration\n",
    "    'federated': {\n",
    "        'num_clients': 10,\n",
    "        'alpha': 0.5,  # Dirichlet concentration for non-IID\n",
    "        'min_samples_per_client': 50\n",
    "    },\n",
    "\n",
    "    # Drift configuration\n",
    "    'drift': {\n",
    "        'injection_round': 25,\n",
    "        'drift_intensity': 0.3,\n",
    "        'affected_clients': [2, 5, 8],  # Which clients get drift\n",
    "        'drift_types': ['label_noise', 'vocab_shift']\n",
    "    },\n",
    "\n",
    "    # Drift detection configuration\n",
    "    'drift_detection': {\n",
    "        'adwin_delta': 0.002,\n",
    "        'mmd_p_val': 0.05,\n",
    "        'mmd_permutations': 100,\n",
    "        'evidently_threshold': 0.25,\n",
    "        'trimmed_beta': 0.2,  # For FedTrimmedAvg\n",
    "    },\n",
    "\n",
    "    # Simulation configuration\n",
    "    'simulation': {\n",
    "        'num_rounds': 50,\n",
    "        'fraction_fit': 1.0,\n",
    "        'fraction_evaluate': 1.0,\n",
    "        'min_fit_clients': 2,\n",
    "        'min_evaluate_clients': 2,\n",
    "        'mitigation_threshold': 0.3  # >30% clients reporting drift\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"âœ… Configuration loaded:\")\n",
    "print(f\"ðŸ“Š Clients: {CONFIG['federated']['num_clients']}\")\n",
    "print(f\"ðŸ”„ Rounds: {CONFIG['simulation']['num_rounds']}\")\n",
    "print(f\"ðŸ’¥ Drift injection: Round {CONFIG['drift']['injection_round']}\")\n",
    "print(f\"ðŸŽ¯ Affected clients: {CONFIG['drift']['affected_clients']}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}